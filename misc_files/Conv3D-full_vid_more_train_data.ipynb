{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "#main_folder = \"C:/Users/kvvip/Udacity_MLND/Capstone/tennis/tennis_vedios/\"\n",
    "main_folder = \"/media/karthik/Windows/Users/kvvip/Udacity_MLND/Capstone/tennis/tennis_vedios/\"\n",
    "\n",
    "def load_datasets(path):\n",
    "    data = load_files(path)\n",
    "    tennis_files = data['filenames']\n",
    "    tennis_targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    return tennis_files, tennis_targets\n",
    "\n",
    "train_files, train_targets = load_datasets(main_folder+\"train/\")\n",
    "valid_files, valid_targets = load_datasets(main_folder + \"valid/\")\n",
    "test_files, test_targets = load_datasets(main_folder + \"test/\")\n",
    "\n",
    "print(train_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 360, 640, 3) (1, 1, 5, 360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def video_to_images(num, video_path, out_shape, num_iters):\n",
    "    # divide the video file into \"num\" equal parts and randomly sample one\n",
    "    # image from each part, thereby, totalling \"num\" images per video file\n",
    "    \n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    #print(nb_frames, frame_h, frame_w, video_path)\n",
    "    \n",
    "    frame_indexs= np.array(range(0,nb_frames+1, int(nb_frames/(num))))\n",
    "    #np.append(frame_indexs,nb_frames)\n",
    "    #print(frame_indexs)\n",
    "    \n",
    "    final_images_set = []\n",
    "    for iteration in range(num_iters):\n",
    "        index_start=0\n",
    "        selected_frames = []\n",
    "        images_out=[]\n",
    "        \n",
    "        for vals in frame_indexs[1:]:\n",
    "            selected_frames.append(random.choice(range(index_start, vals)))\n",
    "            index_start = vals\n",
    "\n",
    "            video_reader.set(1, selected_frames[-1])\n",
    "            ret, image = video_reader.read()\n",
    "\n",
    "            #print(image.shape)\n",
    "            input_image = cv2.resize(image, out_shape)\n",
    "            #print(input_image.shape)\n",
    "            input_image = input_image/ 255 #normalizing\n",
    "            input_image=list(input_image)\n",
    "            images_out.append(input_image)\n",
    "        \n",
    "        final_images_set.append(images_out)\n",
    "    \n",
    "    \n",
    "    #images_out  = np.array(images_out)\n",
    "    final_images_set=np.array(final_images_set)\n",
    "    \n",
    "    video_reader.release()\n",
    "    \n",
    "    return final_images_set\n",
    "        \n",
    "    #print(selected_frames)\n",
    "    \n",
    "    \n",
    "    \n",
    "out_images = video_to_images(5, train_files[0], (640, 360),1)\n",
    "print(out_images.shape, np.expand_dims(out_images, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 1115506.38it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 41.80it/s]\n",
      "100%|██████████| 101/101 [00:02<00:00, 41.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#potentital for parallel processing... not doing it here\n",
    "\n",
    "def get_tensors(num_per_video, image_size_tuple, num_iterations, files):\n",
    "    final_tensors= (video_to_images(num_per_video, files[0], image_size_tuple, num_iterations))\n",
    "    #print(np.array(final_tensors).shape)\n",
    "    #final_tensors = []\n",
    "    for file in tqdm(files[1:]):\n",
    "        final_tensors = np.vstack((final_tensors, video_to_images(num_per_video, file, image_size_tuple, num_iterations)))\n",
    "        #final_tensors.append(video_to_images(num_per_video, file, image_size_tuple, num_iterations))\n",
    "\n",
    "        #print(np.array(final_tensors).shape)\n",
    "    return np.array(final_tensors)\n",
    "\n",
    "def get_targets(targets, num_iters):\n",
    "    final_targets =[]\n",
    "    for target in tqdm(targets):\n",
    "        for vals in range(num_iters):\n",
    "            final_targets.append(target)\n",
    "    \n",
    "    return np.array(final_targets)\n",
    "    \n",
    "\n",
    "#train_tensors = get_tensors(5, (200,200), 5, train_files[:])\n",
    "train_targets = get_targets(train_targets, 5)\n",
    "\n",
    "#train_target\n",
    "#train_tensors = np.array([video_to_images(5, path_ , (299,299)) for path_ in tqdm(train_files)])\n",
    "valid_tensors = np.array([np.squeeze(video_to_images(5, path_ , (200,200), 1)) for path_ in tqdm(valid_files)])\n",
    "test_tensors = np.array([np.squeeze(video_to_images(5, path_ , (200,200), 1)) for path_ in tqdm(test_files)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 5, 200, 200, 3) <class 'numpy.ndarray'>\n",
      "(1500, 3) <class 'numpy.ndarray'>\n",
      "(100, 5, 200, 200, 3) <class 'numpy.ndarray'>\n",
      "(101, 5, 200, 200, 3) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(train_tensors.shape, type(train_tensors))\n",
    "print(train_targets.shape, type(train_targets))\n",
    "print(valid_tensors.shape, type(valid_tensors))\n",
    "print(test_tensors.shape, type(test_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_7 (Conv3D)            (None, 5, 100, 100, 8)    200       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 5, 50, 50, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 5, 25, 25, 16)     1040      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 5, 12, 12, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 5, 6, 6, 32)       4128      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 2, 3, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 2, 2, 2, 64)       16448     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 22,011\n",
      "Trainable params: 22,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ninput_video = Input(shape=(5, 180, 320, 3))\\n\\n#layer1\\nx=Conv3D(8, (2,2,2), strides=(1,2,2), padding='same', name='conv_1', use_bias=True)(input_video)\\n#x = BatchNormalization(name='norm_1')(x)\\n#x = LeakyReLU(alpha=0.1)(x)\\nx = AveragePooling3D(pool_size=(1, 2, 2))(x)\\n\\nprint(x.shape)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv3D, MaxPooling3D, GlobalAveragePooling3D,MaxPooling2D, Conv2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Input, AveragePooling3D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model.add(Conv2D(8, (2,2), strides=2, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(16, (2,2), strides=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(32, (2,2), strides=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(8, (2,2,2), strides=(1,2,2), padding='same', activation='relu', input_shape=(5, 200, 200, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(16, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(32, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(64, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input_video = Input(shape=(5, 180, 320, 3))\n",
    "\n",
    "#layer1\n",
    "x=Conv3D(8, (2,2,2), strides=(1,2,2), padding='same', name='conv_1', use_bias=True)(input_video)\n",
    "#x = BatchNormalization(name='norm_1')(x)\n",
    "#x = LeakyReLU(alpha=0.1)(x)\n",
    "x = AveragePooling3D(pool_size=(1, 2, 2))(x)\n",
    "\n",
    "print(x.shape)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 100 samples\n",
      "Epoch 1/30\n",
      "Epoch 00001: val_loss improved from inf to 1.06157, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 5s - loss: 1.0788 - acc: 0.4140 - val_loss: 1.0616 - val_acc: 0.4200\n",
      "Epoch 2/30\n",
      "Epoch 00002: val_loss improved from 1.06157 to 1.05087, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 4s - loss: 1.0478 - acc: 0.4387 - val_loss: 1.0509 - val_acc: 0.4200\n",
      "Epoch 3/30\n",
      "Epoch 00003: val_loss improved from 1.05087 to 0.91229, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 4s - loss: 0.9082 - acc: 0.5473 - val_loss: 0.9123 - val_acc: 0.5500\n",
      "Epoch 4/30\n",
      "Epoch 00004: val_loss improved from 0.91229 to 0.90216, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 4s - loss: 0.7325 - acc: 0.6640 - val_loss: 0.9022 - val_acc: 0.5300\n",
      "Epoch 5/30\n",
      "Epoch 00005: val_loss improved from 0.90216 to 0.88461, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 5s - loss: 0.6700 - acc: 0.6840 - val_loss: 0.8846 - val_acc: 0.5900\n",
      "Epoch 6/30\n",
      "Epoch 00006: val_loss improved from 0.88461 to 0.84311, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 4s - loss: 0.6020 - acc: 0.7407 - val_loss: 0.8431 - val_acc: 0.6000\n",
      "Epoch 7/30\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 4s - loss: 0.5432 - acc: 0.7693 - val_loss: 0.8608 - val_acc: 0.6700\n",
      "Epoch 8/30\n",
      "Epoch 00008: val_loss improved from 0.84311 to 0.80973, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      " - 5s - loss: 0.4755 - acc: 0.7980 - val_loss: 0.8097 - val_acc: 0.6300\n",
      "Epoch 9/30\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 4s - loss: 0.3933 - acc: 0.8553 - val_loss: 0.8641 - val_acc: 0.6900\n",
      "Epoch 10/30\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 4s - loss: 0.3465 - acc: 0.8647 - val_loss: 0.9264 - val_acc: 0.6300\n",
      "Epoch 11/30\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 5s - loss: 0.2924 - acc: 0.8853 - val_loss: 0.9174 - val_acc: 0.6700\n",
      "Epoch 12/30\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 5s - loss: 0.2182 - acc: 0.9160 - val_loss: 1.1560 - val_acc: 0.5900\n",
      "Epoch 13/30\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 5s - loss: 0.1845 - acc: 0.9347 - val_loss: 1.0089 - val_acc: 0.6500\n",
      "Epoch 14/30\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 5s - loss: 0.1522 - acc: 0.9540 - val_loss: 1.4145 - val_acc: 0.6100\n",
      "Epoch 15/30\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 5s - loss: 0.1091 - acc: 0.9727 - val_loss: 1.2304 - val_acc: 0.7200\n",
      "Epoch 16/30\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 4s - loss: 0.0745 - acc: 0.9833 - val_loss: 1.3767 - val_acc: 0.7000\n",
      "Epoch 17/30\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 5s - loss: 0.0549 - acc: 0.9913 - val_loss: 1.4937 - val_acc: 0.6800\n",
      "Epoch 18/30\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 5s - loss: 0.0463 - acc: 0.9900 - val_loss: 1.4667 - val_acc: 0.7100\n",
      "Epoch 19/30\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 5s - loss: 0.0273 - acc: 0.9993 - val_loss: 1.6789 - val_acc: 0.6500\n",
      "Epoch 20/30\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 5s - loss: 0.0257 - acc: 0.9967 - val_loss: 1.8309 - val_acc: 0.6500\n",
      "Epoch 21/30\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 5s - loss: 0.0166 - acc: 0.9993 - val_loss: 1.7970 - val_acc: 0.6300\n",
      "Epoch 22/30\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 5s - loss: 0.0164 - acc: 0.9993 - val_loss: 1.8086 - val_acc: 0.6900\n",
      "Epoch 23/30\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 5s - loss: 0.0154 - acc: 0.9987 - val_loss: 2.0484 - val_acc: 0.6600\n",
      "Epoch 24/30\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 5s - loss: 0.0093 - acc: 1.0000 - val_loss: 2.0010 - val_acc: 0.6800\n",
      "Epoch 25/30\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 5s - loss: 0.0050 - acc: 1.0000 - val_loss: 2.0505 - val_acc: 0.6800\n",
      "Epoch 26/30\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 5s - loss: 0.0040 - acc: 1.0000 - val_loss: 2.0816 - val_acc: 0.6700\n",
      "Epoch 27/30\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 5s - loss: 0.0033 - acc: 1.0000 - val_loss: 2.1203 - val_acc: 0.6900\n",
      "Epoch 28/30\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 5s - loss: 0.0029 - acc: 1.0000 - val_loss: 2.1848 - val_acc: 0.6900\n",
      "Epoch 29/30\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 5s - loss: 0.0026 - acc: 1.0000 - val_loss: 2.2200 - val_acc: 0.6800\n",
      "Epoch 30/30\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 5s - loss: 0.0024 - acc: 1.0000 - val_loss: 2.2035 - val_acc: 0.6700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59c519acf8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 69.3069%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "tennis_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(tennis_predictions)==np.argmax(test_targets, axis=1))/len(tennis_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "input_tensor = Input(shape=(200, 200, 3))\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 200, 200, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 99, 99, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 99, 99, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 99, 99, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 97, 97, 32)   9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 97, 97, 32)   96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 97, 97, 32)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 97, 97, 64)   18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 97, 97, 64)   192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 97, 97, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 48, 48, 64)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 48, 48, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 48, 48, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 48, 48, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 46, 46, 192)  138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 46, 46, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 46, 46, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 22, 22, 192)  0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 22, 22, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 22, 22, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 22, 22, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 22, 22, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 22, 22, 96)   55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 22, 22, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 22, 22, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 22, 22, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 22, 22, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 22, 22, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 22, 22, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 22, 22, 64)   76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 22, 22, 96)   82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 22, 22, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 22, 22, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 22, 22, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 22, 22, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 22, 22, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 22, 22, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 22, 22, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 22, 22, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 22, 22, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 22, 22, 256)  0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 22, 22, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 22, 22, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 22, 22, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 22, 22, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 22, 22, 96)   55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 22, 22, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 22, 22, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 22, 22, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 22, 22, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 22, 22, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 22, 22, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 22, 22, 64)   76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 22, 22, 96)   82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 22, 22, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 22, 22, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 22, 22, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 22, 22, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 22, 22, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 22, 22, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 22, 22, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 22, 22, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 22, 22, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 22, 22, 288)  0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 22, 22, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 22, 22, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 22, 22, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 22, 22, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 22, 22, 96)   55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 22, 22, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 22, 22, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 22, 22, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 22, 22, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 22, 22, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 22, 22, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 22, 22, 64)   76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 22, 22, 96)   82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 22, 22, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 22, 22, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 22, 22, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 22, 22, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 22, 22, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 22, 22, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 22, 22, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 22, 22, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 22, 22, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 22, 22, 288)  0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 22, 22, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 22, 22, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 22, 22, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 22, 22, 96)   55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 22, 22, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 22, 22, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 10, 10, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 10, 10, 96)   82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 10, 10, 384)  1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 10, 10, 96)   288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 10, 10, 384)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 10, 10, 96)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 10, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 10, 10, 768)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 10, 10, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 10, 10, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 10, 10, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 10, 10, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 10, 10, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 10, 10, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 10, 10, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 10, 10, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 10, 10, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 10, 10, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 10, 10, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 10, 10, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 10, 10, 128)  114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 10, 10, 128)  114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 10, 10, 128)  384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 10, 10, 128)  384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 10, 10, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 10, 10, 128)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 10, 10, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 10, 10, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 10, 10, 192)  172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 10, 10, 192)  172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 10, 10, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 10, 10, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 10, 10, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 10, 10, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 10, 10, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 10, 10, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 10, 10, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 10, 10, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 10, 10, 768)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 10, 10, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 10, 10, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 10, 10, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 10, 10, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 10, 10, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 10, 10, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 10, 10, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 10, 10, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 10, 10, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 10, 10, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 10, 10, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 10, 10, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 10, 10, 160)  179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 10, 10, 160)  179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 10, 10, 160)  480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 10, 10, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 10, 10, 160)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 10, 10, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 10, 10, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 10, 10, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 10, 10, 192)  215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 10, 10, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 10, 10, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 10, 10, 192)  576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 10, 10, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 10, 10, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 10, 10, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 10, 10, 192)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 10, 10, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 10, 10, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 10, 10, 768)  0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 10, 10, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 10, 10, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 10, 10, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 10, 10, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 10, 10, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 10, 10, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 10, 10, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 10, 10, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 10, 10, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 10, 10, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 10, 10, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 10, 10, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 10, 10, 160)  179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 10, 10, 160)  179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 10, 10, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 10, 10, 160)  480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 10, 10, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 10, 10, 160)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 10, 10, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 10, 10, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 10, 10, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 10, 10, 192)  215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 10, 10, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 10, 10, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 10, 10, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 10, 10, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 10, 10, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 10, 10, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 10, 10, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 10, 10, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 10, 10, 768)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 10, 10, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 10, 10, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 10, 10, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 10, 10, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 10, 10, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 10, 10, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 10, 10, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 10, 10, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 10, 10, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 10, 10, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 10, 10, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 10, 10, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 10, 10, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 10, 10, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 10, 10, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 10, 10, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 10, 10, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 10, 10, 192)  258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 10, 10, 192)  258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 10, 10, 192)  147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 10, 10, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 10, 10, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 10, 10, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 10, 10, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 10, 10, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 10, 10, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 10, 10, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 10, 10, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 10, 10, 768)  0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 10, 10, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 10, 10, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 10, 10, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 10, 10, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 10, 10, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 10, 10, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 10, 10, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 10, 10, 192)  258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 10, 10, 192)  576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 10, 10, 192)  576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 10, 10, 192)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 10, 10, 192)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 4, 4, 320)    552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 4, 4, 192)    331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 4, 4, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 4, 4, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 4, 4, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 4, 4, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 4, 4, 1280)   0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 4, 4, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 4, 4, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 4, 4, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 4, 4, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 4, 4, 384)    1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 4, 4, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 4, 4, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 4, 4, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 4, 4, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 4, 4, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 4, 4, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 4, 4, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 4, 4, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 4, 4, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 4, 4, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 4, 4, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 4, 4, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 4, 4, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 4, 4, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 4, 4, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 4, 4, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 4, 4, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 4, 4, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 4, 4, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 4, 4, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 4, 4, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 4, 4, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 4, 4, 768)    0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 768)    0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 4, 4, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 4, 4, 2048)   0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 4, 4, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 4, 4, 448)    1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 4, 4, 448)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 4, 4, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 4, 4, 384)    1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 4, 4, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 4, 4, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 4, 4, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 4, 4, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 4, 4, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 4, 4, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 4, 4, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 4, 4, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 4, 4, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 4, 4, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 4, 4, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 4, 4, 384)    1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 4, 4, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 4, 4, 384)    1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 4, 4, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 4, 4, 320)    960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 4, 4, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 4, 4, 384)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 4, 4, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 4, 4, 384)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 4, 4, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 4, 4, 320)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 4, 4, 768)    0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 768)    0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 4, 4, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 4, 4, 2048)   0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.92s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.00it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 5, 4, 4, 2048) (100, 5, 4, 4, 2048) (101, 5, 4, 4, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def bottleneck_feature_extractor(inp_tensors, model_used, length=1500, num_images=5):\n",
    "    \n",
    "    #train tensors are of shape (300, 5, 299,299,3)\n",
    "    #copy_inp_tensors = inp_tensors.copy()\n",
    "    #copy_inp_tensors = np.array(np.squeeze(np.split(inp_tensors, num_images, axis=1)))\n",
    "    copy_inp_tensors= np.reshape(inp_tensors, (num_images, length, 200, 200, 3))\n",
    "    #copy_inp_tensors of shape (5, 300, 299,299,3)\n",
    "    bottleneck_features=[]\n",
    "    for frame_images in tqdm(copy_inp_tensors):\n",
    "        bottleneck_features.append(model_used.predict(frame_images))\n",
    "        \n",
    "    #BNeck_tensors1 = np.squeeze(np.split(np.array(bottleneck_features), length, axis=1))\n",
    "    bottleneck_features = np.array(bottleneck_features)\n",
    "    a,b,c,d,e = bottleneck_features.shape\n",
    "    BNeck_tensors = np.reshape(bottleneck_features, (b, a, c, d, e))\n",
    "    #print(BNeck_tensors == BNeck_tensors1)\n",
    "    return BNeck_tensors\n",
    "\n",
    "\n",
    "train_BNeck_tensors = bottleneck_feature_extractor(train_tensors, base_model)\n",
    "valid_BNeck_tensors = bottleneck_feature_extractor(valid_tensors, base_model, len(valid_tensors),5)\n",
    "test_BNeck_tensors = bottleneck_feature_extractor(test_tensors, base_model, len(test_tensors), 5)\n",
    "\n",
    "print(train_BNeck_tensors.shape, valid_BNeck_tensors.shape, test_BNeck_tensors.shape)\n",
    "   \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_37 (Conv3D)           (None, 256, 2, 2, 1024)   10496     \n",
      "_________________________________________________________________\n",
      "conv3d_38 (Conv3D)           (None, 256, 1, 1, 512)    524544    \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 393219    \n",
      "=================================================================\n",
      "Total params: 928,259\n",
      "Trainable params: 928,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BNeck_model = Sequential()\n",
    "BNeck_model.add(Conv3D(256, (2,2,2), strides=(2,2,2), padding='same', activation='relu', input_shape=(5, 4, 4, 2048), data_format=\"channels_first\"))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_first\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "BNeck_model.add(Conv3D(256, (2,2,2), strides=(2,2,2), padding='same', activation='relu', data_format=\"channels_first\"))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_first\"))\n",
    "model.add(Dropout(0.95))\n",
    "\n",
    "#BNeck_model.add(Conv3D(32, (2,2,2), strides=(2,2,2), padding='same', activation='relu'))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#BNeck_model.add(Conv3D(64, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "\n",
    "\n",
    "BNeck_model.add(Flatten())\n",
    "#BNeck_model.add(Dense(5, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "BNeck_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "BNeck_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.75870, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 4s - loss: 0.7378 - acc: 0.6853 - val_loss: 0.7587 - val_acc: 0.6300\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 3s - loss: 0.1235 - acc: 0.9607 - val_loss: 0.7759 - val_acc: 0.7300\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.75870 to 0.70097, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 3s - loss: 0.0228 - acc: 0.9927 - val_loss: 0.7010 - val_acc: 0.7300\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 3s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.9568 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 3s - loss: 6.7052e-04 - acc: 1.0000 - val_loss: 1.0380 - val_acc: 0.7700\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 3s - loss: 2.8013e-04 - acc: 1.0000 - val_loss: 1.0856 - val_acc: 0.7600\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 3s - loss: 1.8831e-04 - acc: 1.0000 - val_loss: 1.1233 - val_acc: 0.7600\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 3s - loss: 1.4198e-04 - acc: 1.0000 - val_loss: 1.1542 - val_acc: 0.7600\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 3s - loss: 1.1386e-04 - acc: 1.0000 - val_loss: 1.1842 - val_acc: 0.7600\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 3s - loss: 9.3855e-05 - acc: 1.0000 - val_loss: 1.2120 - val_acc: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f575ddb96a0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNeck_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_InceptionV3.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "BNeck_model.fit(train_BNeck_tensors, train_targets, \n",
    "          validation_data=(valid_BNeck_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 79.2079%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "tennis_predictions = [np.argmax(BNeck_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_BNeck_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(tennis_predictions)==np.argmax(test_targets, axis=1))/len(tennis_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-f28b1a7c9422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_BNeck_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck_feature_extractor_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mvalid_BNeck_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck_feature_extractor_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_BNeck_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck_feature_extractor_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-f28b1a7c9422>\u001b[0m in \u001b[0;36mbottleneck_feature_extractor_avg\u001b[0;34m(inp_tensors, model_used, length, num_images)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbottleneck_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe_images\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_inp_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel_used\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(model_used)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mbottleneck_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_used\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "def bottleneck_feature_extractor_avg(inp_tensors, model_used, length=300, num_images=5):\n",
    "    \n",
    "    #train tensors are of shape (300, 5, 299,299,3)\n",
    "    #copy_inp_tensors = inp_tensors.copy()\n",
    "    #copy_inp_tensors = np.array(np.squeeze(np.split(inp_tensors, num_images, axis=1)))\n",
    "    copy_inp_tensors= np.reshape(inp_tensors, (num_images, length, 299, 299, 3))\n",
    "    #copy_inp_tensors of shape (5, 300, 299,299,3)\n",
    "    bottleneck_features=[]\n",
    "    for frame_images in tqdm(copy_inp_tensors):\n",
    "        model_used.add(GlobalAveragePooling2D())#(model_used)\n",
    "        bottleneck_features.append(model_used.predict(frame_images))\n",
    "        \n",
    "    #BNeck_tensors1 = np.squeeze(np.split(np.array(bottleneck_features), length, axis=1))\n",
    "    bottleneck_features = np.array(bottleneck_features)\n",
    "    a,b,c,d,e = bottleneck_features.shape\n",
    "    BNeck_tensors = np.reshape(bottleneck_features, (b, a, c, d, e))\n",
    "    #print(BNeck_tensors == BNeck_tensors1)\n",
    "    return BNeck_tensors\n",
    "\n",
    "\n",
    "train_BNeck_tensors = bottleneck_feature_extractor_avg(train_tensors, base_model)\n",
    "valid_BNeck_tensors = bottleneck_feature_extractor_avg(valid_tensors, base_model, len(valid_tensors),5)\n",
    "test_BNeck_tensors = bottleneck_feature_extractor_avg(test_tensors, base_model, len(test_tensors), 5)\n",
    "\n",
    "print(train_BNeck_tensors.shape, valid_BNeck_tensors.shape, test_BNeck_tensors.shape)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
