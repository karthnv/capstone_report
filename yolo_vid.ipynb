{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "#main_folder = \"C:/Users/kvvip/Udacity_MLND/Capstone/tennis/tennis_vedios/\"\n",
    "#main_folder = \"/media/karthik/Windows/Users/kvvip/Udacity_MLND/Capstone/Capstone_Udacity/\"\n",
    "main_folder = \"\" #main folder is current folder\n",
    "\n",
    "def load_datasets(path):\n",
    "    data = load_files(path)\n",
    "    tennis_files = data['filenames']\n",
    "    tennis_targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    return tennis_files, tennis_targets\n",
    "\n",
    "train_files, train_targets = load_datasets(main_folder+\"train_yolo/\")\n",
    "valid_files, valid_targets = load_datasets(main_folder + \"valid_yolo/\")\n",
    "test_files, test_targets = load_datasets(main_folder + \"test_yolo/\")\n",
    "\n",
    "#print(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 360, 640, 3) (1, 5, 360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def video_to_images(num, video_path, out_shape):\n",
    "    # divide the video file into \"num\" equal parts and randomly sample one\n",
    "    # image from each part, thereby, totalling \"num\" images per video file\n",
    "    \n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    #print(nb_frames, frame_h, frame_w, video_path)\n",
    "    \n",
    "    frame_indexs= list(np.array(range(0,nb_frames+1, round(nb_frames/(num)))))\n",
    "    #np.append(frame_indexs,nb_frames)\n",
    "    #print(frame_indexs)\n",
    "    \n",
    "    if len(frame_indexs) != (num + 1):\n",
    "        frame_indexs.append(nb_frames)\n",
    "    \n",
    "    frame_indexs = np.array(frame_indexs)\n",
    "    \n",
    "    index_start=0\n",
    "    selected_frames = []\n",
    "    images_out=np.array([])\n",
    "    #print(frame_indexs)\n",
    "    for vals in frame_indexs[1:]:\n",
    "        selected_frames.append(random.choice(range(index_start, vals)))\n",
    "        index_start = vals\n",
    "        \n",
    "        video_reader.set(1, selected_frames[-1])\n",
    "        ret, image = video_reader.read()\n",
    "        \n",
    "        #print(image.shape)\n",
    "        input_image = cv2.resize(image, out_shape)\n",
    "        #print(input_image.shape)\n",
    "        input_image = input_image/ 255 #normalizing\n",
    "        #input_image=list(input_image)\n",
    "        try:\n",
    "            images_out = np.append(images_out,np.expand_dims(input_image, axis=0), axis=0)\n",
    "            #print(images_out.shape, \"here\")\n",
    "        except:\n",
    "            images_out= np.array(np.expand_dims(input_image, axis=0))\n",
    "            #print(\"except\", images_out.shape)\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    #images_out  = np.expand_dims(images_out, axis=0)\n",
    "    video_reader.release()\n",
    "    \n",
    "    #print(images_out.shape)\n",
    "    \n",
    "    return images_out\n",
    "        \n",
    "    #print(selected_frames)\n",
    "    \n",
    "    \n",
    "    \n",
    "out_images = video_to_images(5, train_files[0], (640, 360))\n",
    "print(out_images.shape, np.expand_dims(out_images, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:05<00:00, 50.96it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.16it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 50.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#creating train, valid and test tensors\n",
    "\n",
    "def get_tensors(files):\n",
    "    \n",
    "    tensors_out = video_to_images(5, files[0] , (299,299))\n",
    "    \n",
    "    for path_ in tqdm(files[1:]):\n",
    "        tensors_out = np.vstack((tensors_out, video_to_images(5, path_ , (299,299))))\n",
    "    \n",
    "    return tensors_out\n",
    "\n",
    "#train_tensors = get_tensors(train_files)\n",
    "#valid_tensors = get_tensors(valid_files)\n",
    "#test_tensors = get_tensors(test_files)\n",
    "        \n",
    "train_tensors = np.array([video_to_images(5, path_ , (299,299)) for path_ in tqdm(train_files)])\n",
    "valid_tensors = np.array([video_to_images(5, path_ , (299,299)) for path_ in tqdm(valid_files)])\n",
    "test_tensors = np.array([video_to_images(5, path_ , (299,299)) for path_ in tqdm(test_files)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 5, 299, 299, 3) <class 'numpy.ndarray'>\n",
      "(100, 5, 299, 299, 3) <class 'numpy.ndarray'>\n",
      "(101, 5, 299, 299, 3) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(train_tensors.shape, type(train_tensors))\n",
    "print(valid_tensors.shape, type(valid_tensors))\n",
    "print(test_tensors.shape, type(test_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 5, 150, 150, 8)    200       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 75, 75, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 38, 38, 16)     1040      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 5, 19, 19, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 5, 10, 10, 32)     4128      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 2, 3, 3, 64)       16448     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 22,011\n",
      "Trainable params: 22,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv3D, MaxPooling3D, GlobalAveragePooling3D,MaxPooling2D, Conv2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Input, AveragePooling3D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(8, (2,2,2), strides=(1,2,2), padding='same', activation='relu', input_shape=(5, 299, 299, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(16, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(32, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv3D(64, (2,2,2), strides=(1,2,2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/20\n",
      "Epoch 00001: val_loss improved from inf to 1.07053, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 3s - loss: 1.0877 - acc: 0.4067 - val_loss: 1.0705 - val_acc: 0.4200\n",
      "Epoch 2/20\n",
      "Epoch 00002: val_loss improved from 1.07053 to 1.06533, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 1.0700 - acc: 0.4200 - val_loss: 1.0653 - val_acc: 0.4200\n",
      "Epoch 3/20\n",
      "Epoch 00003: val_loss improved from 1.06533 to 1.05536, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 1.0609 - acc: 0.4500 - val_loss: 1.0554 - val_acc: 0.4200\n",
      "Epoch 4/20\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 1.0545 - acc: 0.4333 - val_loss: 1.0581 - val_acc: 0.4200\n",
      "Epoch 5/20\n",
      "Epoch 00005: val_loss improved from 1.05536 to 1.02224, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 1.0352 - acc: 0.4200 - val_loss: 1.0222 - val_acc: 0.4200\n",
      "Epoch 6/20\n",
      "Epoch 00006: val_loss improved from 1.02224 to 0.98368, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.9847 - acc: 0.5900 - val_loss: 0.9837 - val_acc: 0.4200\n",
      "Epoch 7/20\n",
      "Epoch 00007: val_loss improved from 0.98368 to 0.93759, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.9230 - acc: 0.5067 - val_loss: 0.9376 - val_acc: 0.5500\n",
      "Epoch 8/20\n",
      "Epoch 00008: val_loss improved from 0.93759 to 0.84903, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.8893 - acc: 0.5400 - val_loss: 0.8490 - val_acc: 0.6700\n",
      "Epoch 9/20\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 2s - loss: 0.8477 - acc: 0.6533 - val_loss: 0.9347 - val_acc: 0.4200\n",
      "Epoch 10/20\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.8003 - acc: 0.6267 - val_loss: 0.8607 - val_acc: 0.5100\n",
      "Epoch 11/20\n",
      "Epoch 00011: val_loss improved from 0.84903 to 0.79077, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.7082 - acc: 0.6800 - val_loss: 0.7908 - val_acc: 0.6200\n",
      "Epoch 12/20\n",
      "Epoch 00012: val_loss improved from 0.79077 to 0.74328, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.6541 - acc: 0.7333 - val_loss: 0.7433 - val_acc: 0.6700\n",
      "Epoch 13/20\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 2s - loss: 0.5986 - acc: 0.7767 - val_loss: 0.8027 - val_acc: 0.6400\n",
      "Epoch 14/20\n",
      "Epoch 00014: val_loss improved from 0.74328 to 0.69720, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.5657 - acc: 0.7833 - val_loss: 0.6972 - val_acc: 0.7000\n",
      "Epoch 15/20\n",
      "Epoch 00015: val_loss improved from 0.69720 to 0.67732, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.4347 - acc: 0.8633 - val_loss: 0.6773 - val_acc: 0.7200\n",
      "Epoch 16/20\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 2s - loss: 0.3919 - acc: 0.8733 - val_loss: 0.8603 - val_acc: 0.6600\n",
      "Epoch 17/20\n",
      "Epoch 00017: val_loss improved from 0.67732 to 0.64257, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 3s - loss: 0.3775 - acc: 0.8833 - val_loss: 0.6426 - val_acc: 0.7200\n",
      "Epoch 18/20\n",
      "Epoch 00018: val_loss improved from 0.64257 to 0.62009, saving model to saved_models/weights.best.from_scratch_yolo.hdf5\n",
      " - 2s - loss: 0.2780 - acc: 0.9267 - val_loss: 0.6201 - val_acc: 0.7400\n",
      "Epoch 19/20\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 2s - loss: 0.2550 - acc: 0.9267 - val_loss: 0.7988 - val_acc: 0.6200\n",
      "Epoch 20/20\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 2s - loss: 0.2498 - acc: 0.9233 - val_loss: 0.7009 - val_acc: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f610d86d748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch_yolo.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch_yolo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 76.2376%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "tennis_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(tennis_predictions)==np.argmax(test_targets, axis=1))/len(tennis_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying InceptionV3 transfer learning and using Conv3d on the reultant tensors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "input_tensor = Input(shape=(299, 299, 3))\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.62s/it]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 5, 8, 8, 2048) (100, 5, 8, 8, 2048) (101, 5, 8, 8, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def bottleneck_feature_extractor(inp_tensors, model_used, length=300, num_images=5):\n",
    "    \n",
    "    #train tensors are of shape (300, 5, 299,299,3)\n",
    "\n",
    "    copy_inp_tensors= np.reshape(inp_tensors, (num_images, length, 299, 299, 3))\n",
    "    #copy_inp_tensors of shape (5, 300, 299,299,3)\n",
    "    bottleneck_features=[]\n",
    "    for frame_images in tqdm(copy_inp_tensors):\n",
    "        bottleneck_features.append(model_used.predict(frame_images))\n",
    "        \n",
    "    #BNeck_tensors1 = np.squeeze(np.split(np.array(bottleneck_features), length, axis=1))\n",
    "    bottleneck_features = np.array(bottleneck_features)\n",
    "    a,b,c,d,e = bottleneck_features.shape\n",
    "    BNeck_tensors = np.reshape(bottleneck_features, (b, a, c, d, e))\n",
    "    #print(BNeck_tensors == BNeck_tensors1)\n",
    "    return BNeck_tensors\n",
    "\n",
    "\n",
    "train_BNeck_tensors = bottleneck_feature_extractor(train_tensors, base_model)\n",
    "valid_BNeck_tensors = bottleneck_feature_extractor(valid_tensors, base_model, len(valid_tensors),5)\n",
    "test_BNeck_tensors = bottleneck_feature_extractor(test_tensors, base_model, len(test_tensors), 5)\n",
    "\n",
    "print(train_BNeck_tensors.shape, valid_BNeck_tensors.shape, test_BNeck_tensors.shape)\n",
    "   \n",
    "        \n",
    "   \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 32, 4, 4, 1024)    1312      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 32, 2, 2, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 64, 1, 1, 256)     16448     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 49155     \n",
      "=================================================================\n",
      "Total params: 66,915\n",
      "Trainable params: 66,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BNeck_model = Sequential()\n",
    "BNeck_model.add(Conv3D(32, (2,2,2), strides=(2,2,2), padding='same', activation='relu', input_shape=(5, 8, 8, 2048), data_format=\"channels_first\"))\n",
    "BNeck_model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_first\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "BNeck_model.add(Conv3D(64, (2,2,2), strides=(2,2,2), padding='same', activation='relu', data_format=\"channels_first\"))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_first\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "#BNeck_model.add(Conv3D(32, (2,2,2), strides=(2,2,2), padding='same', activation='relu'))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(2,2,2), strides=None, padding='valid', data_format=\"channels_last\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "BNeck_model.add(Flatten())\n",
    "#BNeck_model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "BNeck_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "BNeck_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/40\n",
      "Epoch 00001: val_loss improved from inf to 0.98139, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 1.2405 - acc: 0.4467 - val_loss: 0.9814 - val_acc: 0.4100\n",
      "Epoch 2/40\n",
      "Epoch 00002: val_loss improved from 0.98139 to 0.58812, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.6770 - acc: 0.7700 - val_loss: 0.5881 - val_acc: 0.8000\n",
      "Epoch 3/40\n",
      "Epoch 00003: val_loss improved from 0.58812 to 0.35737, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.2999 - acc: 0.9367 - val_loss: 0.3574 - val_acc: 0.8800\n",
      "Epoch 4/40\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 1s - loss: 0.1195 - acc: 0.9700 - val_loss: 0.3962 - val_acc: 0.8500\n",
      "Epoch 5/40\n",
      "Epoch 00005: val_loss improved from 0.35737 to 0.18929, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0734 - acc: 0.9900 - val_loss: 0.1893 - val_acc: 0.9300\n",
      "Epoch 6/40\n",
      "Epoch 00006: val_loss improved from 0.18929 to 0.17114, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0318 - acc: 0.9967 - val_loss: 0.1711 - val_acc: 0.9500\n",
      "Epoch 7/40\n",
      "Epoch 00007: val_loss improved from 0.17114 to 0.14878, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.1488 - val_acc: 0.9400\n",
      "Epoch 8/40\n",
      "Epoch 00008: val_loss improved from 0.14878 to 0.14161, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9500\n",
      "Epoch 9/40\n",
      "Epoch 00009: val_loss improved from 0.14161 to 0.13538, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9400\n",
      "Epoch 10/40\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9400\n",
      "Epoch 11/40\n",
      "Epoch 00011: val_loss improved from 0.13538 to 0.13318, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9400\n",
      "Epoch 12/40\n",
      "Epoch 00012: val_loss improved from 0.13318 to 0.12972, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9400\n",
      "Epoch 13/40\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9400\n",
      "Epoch 14/40\n",
      "Epoch 00014: val_loss improved from 0.12972 to 0.12758, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9400\n",
      "Epoch 15/40\n",
      "Epoch 00015: val_loss improved from 0.12758 to 0.12367, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1237 - val_acc: 0.9400\n",
      "Epoch 16/40\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9400\n",
      "Epoch 17/40\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9400\n",
      "Epoch 18/40\n",
      "Epoch 00018: val_loss improved from 0.12367 to 0.12160, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9400\n",
      "Epoch 19/40\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9400\n",
      "Epoch 20/40\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9400\n",
      "Epoch 21/40\n",
      "Epoch 00021: val_loss improved from 0.12160 to 0.11876, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 9.7860e-04 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9400\n",
      "Epoch 22/40\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 1s - loss: 8.7609e-04 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9400\n",
      "Epoch 23/40\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 1s - loss: 8.2641e-04 - acc: 1.0000 - val_loss: 0.1194 - val_acc: 0.9400\n",
      "Epoch 24/40\n",
      "Epoch 00024: val_loss improved from 0.11876 to 0.11797, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 7.6181e-04 - acc: 1.0000 - val_loss: 0.1180 - val_acc: 0.9400\n",
      "Epoch 25/40\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 1s - loss: 7.5688e-04 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9400\n",
      "Epoch 26/40\n",
      "Epoch 00026: val_loss improved from 0.11797 to 0.11766, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 6.6518e-04 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9400\n",
      "Epoch 27/40\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 1s - loss: 5.9762e-04 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9400\n",
      "Epoch 28/40\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 1s - loss: 5.7958e-04 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9400\n",
      "Epoch 29/40\n",
      "Epoch 00029: val_loss improved from 0.11766 to 0.11480, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 5.3065e-04 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9400\n",
      "Epoch 30/40\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 1s - loss: 4.9977e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9400\n",
      "Epoch 31/40\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 1s - loss: 4.7170e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9400\n",
      "Epoch 32/40\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 1s - loss: 4.4856e-04 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9400\n",
      "Epoch 33/40\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 1s - loss: 4.3421e-04 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9400\n",
      "Epoch 34/40\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 1s - loss: 4.1064e-04 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9400\n",
      "Epoch 35/40\n",
      "Epoch 00035: val_loss improved from 0.11480 to 0.11383, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 3.7726e-04 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9400\n",
      "Epoch 36/40\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 1s - loss: 3.5620e-04 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9400\n",
      "Epoch 37/40\n",
      "Epoch 00037: val_loss improved from 0.11383 to 0.11334, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 3.3774e-04 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9400\n",
      "Epoch 38/40\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 1s - loss: 3.2379e-04 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9400\n",
      "Epoch 39/40\n",
      "Epoch 00039: val_loss improved from 0.11334 to 0.11323, saving model to saved_models/weights.best.from_InceptionV3_yolo.hdf5\n",
      " - 1s - loss: 3.0794e-04 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9400\n",
      "Epoch 40/40\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 1s - loss: 2.9200e-04 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f7009bb38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNeck_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_InceptionV3_yolo.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "BNeck_model.fit(train_BNeck_tensors, train_targets, \n",
    "          validation_data=(valid_BNeck_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91.0891%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "tennis_predictions = [np.argmax(BNeck_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_BNeck_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(tennis_predictions)==np.argmax(test_targets, axis=1))/len(tennis_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying InceptionV3 transfer learning and using Concatenation+Conv2D model on the reultant tensors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 40, 8, 2048) (100, 40, 8, 2048) (101, 40, 8, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "def bottleneck_feature_extractor(inp_tensors, model_used, length=300, num_images=5):\n",
    "    \n",
    "    #train tensors are of shape (300, 5, 299,299,3)\n",
    "    copy_inp_tensors= np.reshape(inp_tensors, (num_images, length, 299, 299, 3))\n",
    "    #copy_inp_tensors of shape (5, 300, 299,299,3)\n",
    "    bottleneck_features=[]\n",
    "    #bottleneck_features = model_used.predict(copy_inp_tensors[0])\n",
    "    for frame_images in tqdm(copy_inp_tensors[:]):\n",
    "        bottleneck_features.append(model_used.predict(frame_images))\n",
    "        #bottleneck_features = Concatenate([bottleneck_features, model_used.predict(frame_images)])\n",
    "        \n",
    "    #BNeck_tensors1 = np.squeeze(np.split(np.array(bottleneck_features), length, axis=1))\n",
    "    bottleneck_features = np.array(bottleneck_features)\n",
    "    #print(bottleneck_features.shape)\n",
    "    a,b,c,d,e = bottleneck_features.shape\n",
    "    BNeck_tensors = np.reshape(bottleneck_features, (b, a, c, d, e))\n",
    "    BNeck_tensors = np.reshape(bottleneck_features, (b, a*c, d, e))\n",
    "    #print(BNeck_tensors == BNeck_tensors1)\n",
    "    #BNeck_tensors = bottleneck_features\n",
    "    return BNeck_tensors\n",
    "\n",
    "\n",
    "train_BNeck_tensors = bottleneck_feature_extractor(train_tensors, base_model)\n",
    "valid_BNeck_tensors = bottleneck_feature_extractor(valid_tensors, base_model, len(valid_tensors),5)\n",
    "test_BNeck_tensors = bottleneck_feature_extractor(test_tensors, base_model, len(test_tensors), 5)\n",
    "\n",
    "print(train_BNeck_tensors.shape, valid_BNeck_tensors.shape, test_BNeck_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_95 (Conv2D)           (None, 40, 8, 32)         524320    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 10, 2, 64)         16448     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 544,611\n",
      "Trainable params: 544,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BNeck_model = Sequential()\n",
    "BNeck_model.add(Conv2D(32, (4,2), strides=(1,1), padding='same', activation='relu', input_shape=(40, 8, 2048)))#, data_format=\"channels_first\"))\n",
    "BNeck_model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'))#, data_format=\"channels_first\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "BNeck_model.add(Conv2D(64, (4,2), strides=(2,2), padding='same', activation='relu'))#, data_format=\"channels_first\"))\n",
    "#BNeck_model.add(MaxPooling3D(pool_size=(1,2,2), strides=None, padding='valid', data_format=\"channels_first\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "\n",
    "BNeck_model.add(Flatten())\n",
    "#BNeck_model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "BNeck_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "BNeck_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/40\n",
      "Epoch 00001: val_loss improved from inf to 0.54490, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 1s - loss: 1.1456 - acc: 0.5500 - val_loss: 0.5449 - val_acc: 0.7900\n",
      "Epoch 2/40\n",
      "Epoch 00002: val_loss improved from 0.54490 to 0.49974, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 0s - loss: 0.2670 - acc: 0.9067 - val_loss: 0.4997 - val_acc: 0.7800\n",
      "Epoch 3/40\n",
      "Epoch 00003: val_loss improved from 0.49974 to 0.25273, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 1s - loss: 0.0661 - acc: 0.9800 - val_loss: 0.2527 - val_acc: 0.9000\n",
      "Epoch 4/40\n",
      "Epoch 00004: val_loss improved from 0.25273 to 0.18194, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 0s - loss: 0.0147 - acc: 1.0000 - val_loss: 0.1819 - val_acc: 0.9300\n",
      "Epoch 5/40\n",
      "Epoch 00005: val_loss improved from 0.18194 to 0.17052, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 0s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9400\n",
      "Epoch 6/40\n",
      "Epoch 00006: val_loss improved from 0.17052 to 0.16720, saving model to saved_models/weights.best.from_InceptionV3.hdf5\n",
      " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1672 - val_acc: 0.9400\n",
      "Epoch 7/40\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9400\n",
      "Epoch 8/40\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9400\n",
      "Epoch 9/40\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9400\n",
      "Epoch 10/40\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9400\n",
      "Epoch 11/40\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 0s - loss: 8.9684e-04 - acc: 1.0000 - val_loss: 0.1758 - val_acc: 0.9400\n",
      "Epoch 12/40\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 0s - loss: 7.7066e-04 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 0.9400\n",
      "Epoch 13/40\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 0s - loss: 6.7560e-04 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9400\n",
      "Epoch 14/40\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 0s - loss: 5.8896e-04 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9400\n",
      "Epoch 15/40\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 0s - loss: 5.1996e-04 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9400\n",
      "Epoch 16/40\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 0s - loss: 4.5879e-04 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9400\n",
      "Epoch 17/40\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 0s - loss: 4.0826e-04 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9400\n",
      "Epoch 18/40\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 0s - loss: 3.6701e-04 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9400\n",
      "Epoch 19/40\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 0s - loss: 3.2988e-04 - acc: 1.0000 - val_loss: 0.1888 - val_acc: 0.9500\n",
      "Epoch 20/40\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 0s - loss: 2.9639e-04 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9400\n",
      "Epoch 21/40\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 0s - loss: 2.6595e-04 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9400\n",
      "Epoch 22/40\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 0s - loss: 2.4313e-04 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9400\n",
      "Epoch 23/40\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 0s - loss: 2.2014e-04 - acc: 1.0000 - val_loss: 0.1955 - val_acc: 0.9400\n",
      "Epoch 24/40\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 0s - loss: 2.0202e-04 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9400\n",
      "Epoch 25/40\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 0s - loss: 1.8380e-04 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.9400\n",
      "Epoch 26/40\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 0s - loss: 1.6939e-04 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9400\n",
      "Epoch 27/40\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 0s - loss: 1.5550e-04 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9400\n",
      "Epoch 28/40\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 0s - loss: 1.4428e-04 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9400\n",
      "Epoch 29/40\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 0s - loss: 1.3420e-04 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9400\n",
      "Epoch 30/40\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 0s - loss: 1.2377e-04 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 0.9300\n",
      "Epoch 31/40\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 0s - loss: 1.1548e-04 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 0.9300\n",
      "Epoch 32/40\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 0s - loss: 1.0825e-04 - acc: 1.0000 - val_loss: 0.2112 - val_acc: 0.9300\n",
      "Epoch 33/40\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 0s - loss: 1.0144e-04 - acc: 1.0000 - val_loss: 0.2124 - val_acc: 0.9300\n",
      "Epoch 34/40\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 0s - loss: 9.5652e-05 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9300\n",
      "Epoch 35/40\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 0s - loss: 8.9948e-05 - acc: 1.0000 - val_loss: 0.2145 - val_acc: 0.9300\n",
      "Epoch 36/40\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 0s - loss: 8.4559e-05 - acc: 1.0000 - val_loss: 0.2155 - val_acc: 0.9300\n",
      "Epoch 37/40\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 0s - loss: 7.9727e-05 - acc: 1.0000 - val_loss: 0.2163 - val_acc: 0.9300\n",
      "Epoch 38/40\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 0s - loss: 7.5201e-05 - acc: 1.0000 - val_loss: 0.2170 - val_acc: 0.9300\n",
      "Epoch 39/40\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 0s - loss: 7.1483e-05 - acc: 1.0000 - val_loss: 0.2183 - val_acc: 0.9300\n",
      "Epoch 40/40\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 0s - loss: 6.7454e-05 - acc: 1.0000 - val_loss: 0.2185 - val_acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f702cbdd8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNeck_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_InceptionV3.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "BNeck_model.fit(train_BNeck_tensors, train_targets, \n",
    "          validation_data=(valid_BNeck_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 92.0792%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "tennis_predictions = [np.argmax(BNeck_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_BNeck_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(tennis_predictions)==np.argmax(test_targets, axis=1))/len(tennis_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
